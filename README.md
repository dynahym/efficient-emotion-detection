# Lightweight CNN Benchmark for Emotion Recognition

*A comparative evaluation of MobileNet (V1/V2/V3), ShuffleNetV2, SqueezeNet, and ShiftNet on facial emotion recognition with FLOPs, parameters, inference time, and carbon footprint.*

## Overview

This project benchmarks several lightweight convolutional architectures on a facial emotion recognition dataset.
The goal is to evaluate **accuracy**, **computational cost**, and **environmental impact** to identify the most efficient models for real-time deployment.

The models implemented and tested:

* **MobileNetV1**
* **MobileNetV2**
* **MobileNetV3 Small**
* **ShuffleNetV2 (0.5xâ€“2.0x)**
* **SqueezeNet**
* **ShiftNet**

All models are implemented **from scratch in PyTorch**, except MobileNetV3 which uses torchvision with input/classifier patches.

---

## Project Structure

```
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ mobilenet_v1.py
â”‚   â”œâ”€â”€ mobilenet_v2.py
â”‚   â”œâ”€â”€ mobilenet_v3.py
â”‚   â”œâ”€â”€ shufflenet_v2.py
â”‚   â”œâ”€â”€ squeezenet.py
â”‚   â”œâ”€â”€ shiftnet.py
â”‚
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ 03_model_evaluation.ipynb      # Full evaluation pipeline
â”‚   â”œâ”€â”€ 04_analysis.ipynb              # Evaluation summarization + plots
â”‚
â”œâ”€â”€ results.json                       # Saved metrics after evaluation
â”œâ”€â”€ README.md
â””â”€â”€ requirements.txt
```

---

## Implemented Architectures

### **ðŸ”¹ MobileNetV1**

Depthwise-separable convolutions for lightweight inference.

### **ðŸ”¹ MobileNetV2**

Inverted residuals + linear bottlenecks.

### **ðŸ”¹ MobileNetV3 (Small)**

Torchvision implementation adapted for grayscale input and 7 classes.

### **ðŸ”¹ ShuffleNetV2**

Channel shuffle + split branches for efficient memory access.

### **ðŸ”¹ SqueezeNet**

Fire modules to reduce parameters (â‰ˆ 50Ã— smaller than AlexNet).

### **ðŸ”¹ ShiftNet**

Implements shift-based spatial operations instead of standard convolution.

---

## ðŸ“ˆ Evaluation Metrics

The evaluation notebook computes:

| Metric                     | Description                               |
| -------------------------- | ----------------------------------------- |
| **Accuracy**               | Emotion classification accuracy           |
| **Inference time (total)** | Total runtime over the test set           |
| **Inference speed**        | Time per sample                           |
| **FLOPs**                  | Total number of floating-point operations |
| **Parameter count**        | Model size                                |
| **Energy consumed (kWh)**  | Converted from GPU power logs             |
| **COâ‚‚ emissions (kg)**     | Carbon footprint estimation               |

Results are stored in `results.json`

---

## Analysis Notebook (`04_analysis.ipynb`)

This notebook:

âœ” Loads `results.json`
âœ” Builds a Pandas summary table
âœ” Plots accuracy bars
âœ” Prints FLOPs / params / carbon impact for all models

---

## Results (Summary)

After evaluation on the FER dataset:

* Lightweight CNNs can achieve strong accuracy (close to MobileNetV3) with **2â€“10Ã— fewer FLOPs**.
* Some classical lightweight models (ShuffleNetV2, MobileNetV2) achieve the **lowest carbon footprint**.
* ShiftNet is extremely fast and efficient due to removal of spatial convolution.

(Detailed numbers appear automatically in generated plots and tables.)

---

## ðŸ”¬ Research Motivation

As ML models grow, **energy and carbon costs** increase. This project shows that:

* Efficient architectures remain competitive
* FLOPs alone do not predict real energy usage
* Carbon metrics should be included in reproducible benchmarks
